{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/guide/rl.html\n",
    "# https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: matplotlib in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (3.5.3)\n",
      "Requirement already satisfied: cloudpickle in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0 in /home/nsambhu/.local/lib/python3.7/site-packages (from stable-baselines3[extra]) (4.7.1)\n",
      "Requirement already satisfied: torch>=1.11 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: pandas in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (1.21.6)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (0.28.1)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.6.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (2.11.2)\n",
      "Requirement already satisfied: tqdm in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (4.66.1)\n",
      "Requirement already satisfied: shimmy[atari]~=0.2.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (0.2.1)\n",
      "Requirement already satisfied: opencv-python in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (4.8.1.78)\n",
      "Requirement already satisfied: rich in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (13.7.0)\n",
      "Requirement already satisfied: pillow in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (9.5.0)\n",
      "Requirement already satisfied: pygame<2.1.3,>=2.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (2.1.2)\n",
      "Requirement already satisfied: psutil in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from stable-baselines3[extra]) (5.9.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/nsambhu/.local/lib/python3.7/site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (6.7.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: click in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (8.1.7)\n",
      "Requirement already satisfied: importlib-resources in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (5.12.0)\n",
      "Requirement already satisfied: requests in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2.31.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from shimmy[atari]~=0.2.1->stable-baselines3[extra]) (0.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.25.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.38.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.60.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/nsambhu/.local/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (47.3.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from torch>=1.11->stable-baselines3[extra]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from torch>=1.11->stable-baselines3[extra]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from torch>=1.11->stable-baselines3[extra]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from torch>=1.11->stable-baselines3[extra]) (8.5.0.96)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from pandas->stable-baselines3[extra]) (2023.3.post1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from rich->stable-baselines3[extra]) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from rich->stable-baselines3[extra]) (2.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/nsambhu/.local/lib/python3.7/site-packages (from importlib-metadata>=4.8.0->gymnasium==0.28.1->stable-baselines3[extra]) (3.15.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
      "Requirement already satisfied: gym in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from gym) (1.21.6)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages (from gym) (2.2.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/nsambhu/.local/lib/python3.7/site-packages (from gym) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/nsambhu/.local/lib/python3.7/site-packages (from importlib-metadata>=4.8.0->gym) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/nsambhu/.local/lib/python3.7/site-packages (from importlib-metadata>=4.8.0->gym) (4.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]\n",
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Neil added\n",
    "import gym \n",
    "# import gymnasium as gym # Neil added\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"CartPole-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CartPole-v0'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:14.0\n",
      "Episode:2 Score:11.0\n",
      "Episode:3 Score:15.0\n",
      "Episode:4 Score:14.0\n",
      "Episode:5 Score:58.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        import time\n",
    "        time.sleep(.01)\n",
    "        action = env.action_space.sample()\n",
    "        # print(env.step(action));break\n",
    "        n_state, reward, done, truncated, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding The Environment\n",
    "https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-push cart to left, 1-push cart to the right\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6158437e+00,  1.1570229e+38,  1.1335742e-02,  2.2054553e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train an RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 784  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009191375 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.00575     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.61        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 447        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00743063 |\n",
      "|    clip_fraction        | 0.0427     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.665     |\n",
      "|    explained_variance   | 0.0798     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16.7       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    value_loss           | 37.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 424         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007136973 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 54.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 408         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009020664 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.608      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 67.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 394         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010853111 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.589      |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 385         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008955801 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005194615 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 372          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051990096 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043275193 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 13.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f18795b6c10>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsambhu/anaconda3/envs/RLC2/lib/python3.7/site-packages/stable_baselines3/common/save_util.py:278: UserWarning: Path 'Training/Saved Models' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nsambhu/github/ReinforcementLearningCourse'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(PPO_path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200.0, 0.0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info [{'TimeLimit.truncated': True, 'terminal_observation': array([ 0.15706605,  0.7064944 ,  0.01706835, -0.5725405 ], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done: \n",
    "        print('info', info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Viewing Logs in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15585/106717345.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_log_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PPO_3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'log_path' is not defined"
     ]
    }
   ],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={training_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Adding a callback to the training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models')\n",
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=190, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best=stop_callback, \n",
    "                             eval_freq=10000, \n",
    "                             best_model_save_path=save_path, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('Training', 'Saved Models', 'best_model')\n",
    "model = PPO.load(model_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Changing Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch=[dict(pi=[128, 128, 128, 128], vf=[128, 128, 128, 128])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, policy_kwargs={'net_arch': net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Using an Alternate Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_path = os.path.join('Training', 'Saved Models', 'DQN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(dqn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(dqn_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
